{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ce090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# librerie\n",
    "import os\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import Subset\n",
    "from data_augmentation import build_balanced_augmented_tensor_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c2b9a446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x191408fa370>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# riproducibilit√†\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55edef3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurazione\n",
    "image_size = 224 # dimensione a cui ridimensionare le immagini\n",
    "noise_std = 0.05 # livello di rumore gaussiano da aggiungere ai dati augmentati\n",
    "train_ratio, val_ratio = 0.7, 0.15  # percentuali per suddividere in train/val/test\n",
    "\n",
    "# percorsi utili\n",
    "base_dir = os.getcwd()  # percorso base\n",
    "data_dir = os.path.join(base_dir, 'data_histo') # percorso dataset\n",
    "# percorso per salvare output\n",
    "output_folder = os.path.join(base_dir, \"shared_augmented_data\")\n",
    "os.makedirs(output_folder, exist_ok=True) # crea se non esiste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaa74a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trasformazioni\n",
    "transform_base = transforms.Compose([\n",
    "    transforms.Resize((image_size, image_size)),  # ridimensiona le immagini\n",
    "    transforms.ToTensor(),                        # converte in tensore\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56eb564",
   "metadata": {},
   "outputs": [],
   "source": [
    "# caricamento e split\n",
    "full_dataset = datasets.ImageFolder(root=data_dir, transform=transform_base)  # carica tutte le immagini con le etichette\n",
    "total_size = len(full_dataset)                                           # numero totale di immagini\n",
    "train_size = int(train_ratio * total_size)\n",
    "val_size = int(val_ratio * total_size)\n",
    "test_size = total_size - train_size - val_size                           # il resto va al test set\n",
    "\n",
    "# suddivisione indici casuale per il train set ma riproducibile\n",
    "train_indices, _, _ = random_split(\n",
    "    list(range(total_size)), [train_size, val_size, test_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "\n",
    "# recupero dei path (e delle classi) delle sole immagini di train\n",
    "train_samples = [full_dataset.samples[i] for i in train_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43cd726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generazione dati augmentati...\n"
     ]
    }
   ],
   "source": [
    "# applicazione data augmentation\n",
    "print(\"Generazione dati augmentati...\")\n",
    "train_imgs, train_labels, _ = build_balanced_augmented_tensor_dataset(\n",
    "    samples=train_samples,\n",
    "    class_names=full_dataset.classes,\n",
    "    image_size=image_size,\n",
    "    mode=\"balance\",             # bilanciamento classi con oversampling\n",
    "    add_noise=True,             # aggiunta di rumore gaussiano alle immagini\n",
    "    noise_std=noise_std         # deviazione standard del rumore\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80357360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dati augmentati salvati in: c:\\Users\\giken\\Documents\\Noemi\\DAML-project\\shared_augmented_data\\augmented_train_data_0.05.pt\n"
     ]
    }
   ],
   "source": [
    "# salvataggio dati augmentati (immagini + etichette) per utilizzo futuro\n",
    "save_path = os.path.join(output_folder, f\"augmented_train_data_{noise_std}.pt\")\n",
    "torch.save({\n",
    "    'images': train_imgs,\n",
    "    'labels': train_labels\n",
    "}, save_path)\n",
    "\n",
    "print(f\"Dati augmentati salvati in: {save_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
